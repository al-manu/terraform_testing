name: Create AWS Resources (S3 Buckets)

on:
  push:
    branches:
      - 'feature/*'  # Trigger on any push to a feature branch

jobs:
  create-resources:
    runs-on: ubuntu-latest
    permissions:
      id-token: write  # Required for OIDC
      contents: read   # Required for checking out the code
    environment:
      name: dev  # Adjust environment (prod, staging, etc.)
    
    env:
      AWS_ROLE_ARN: ${{ secrets.AWS_DEV_ROLE_ARN }}  # Use the AWS role for dev
      AWS_REGION: ${{ secrets.AWS_REGION }}  # Use the AWS region from secrets

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up AWS credentials using OIDC authentication
      - name: Set up AWS OIDC credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}  # Use the environment variable for AWS role ARN
          aws-region: ${{ env.AWS_REGION }}  # Use the environment variable for AWS region

      # Step 3: Create or verify existence of S3 buckets for Terraform state and lock
      - name: Create or verify S3 buckets
        run: |
          # Define project name and environment (e.g., dev)
          PROJECT_NAME="dw-test"
          ENVIRONMENT="dev"  # This can change to prod, staging, etc.
          REGION="${{ secrets.AWS_REGION }}"  # Get the region from secrets

          # Function to check if the bucket exists, and create if necessary
          create_bucket_if_needed() {
            local BUCKET_NAME=$1
            echo "Checking if the bucket $BUCKET_NAME exists..."
            BUCKET_EXISTS=$(aws s3api head-bucket --bucket "$BUCKET_NAME" --region "$REGION" 2>&1 || true)
            
            # If the bucket does not exist, create it
            if [[ "$BUCKET_EXISTS" == *"NotFound"* ]]; then
              echo "Bucket $BUCKET_NAME does not exist. Creating it..."
              aws s3api create-bucket --bucket "$BUCKET_NAME" --create-bucket-configuration LocationConstraint=$REGION
            else
              echo "Bucket $BUCKET_NAME already exists. Skipping creation."
            fi
          }

          # Define the state and lock bucket names
          STATE_BUCKET_NAME="${PROJECT_NAME}-state-${ENVIRONMENT}"
          LOCK_BUCKET_NAME="${PROJECT_NAME}-lock-${ENVIRONMENT}"

          # Create or verify state and lock buckets
          create_bucket_if_needed "$STATE_BUCKET_NAME"
          create_bucket_if_needed "$LOCK_BUCKET_NAME"

          # Add a short delay to ensure bucket is fully registered (in case of eventual consistency)
          echo "Waiting for the buckets to be fully available..."
          sleep 10  # Wait for 10 seconds to ensure AWS propagates the bucket status

          # Enable versioning on both buckets after creation
          enable_versioning() {
            local BUCKET_NAME=$1
            echo "Enabling versioning for $BUCKET_NAME..."
            aws s3api put-bucket-versioning --bucket "$BUCKET_NAME" --versioning-configuration Status=Enabled --region "$REGION"
          }

          # Enable versioning on both buckets
          enable_versioning "$STATE_BUCKET_NAME"
          enable_versioning "$LOCK_BUCKET_NAME"

          echo "State and lock buckets created or verified: $STATE_BUCKET_NAME, $LOCK_BUCKET_NAME"

      # Step 4: Run Terraform to generate the state file
      - name: Run Terraform to generate state file
        run: |
          echo "Running Terraform to generate the state file..."
          
          terraform init  # Initialize Terraform configuration
          terraform apply -auto-approve  # Apply the configuration (creates the state file)

      # Step 5: Upload Terraform state file to S3
      - name: Upload Terraform state file to S3
        run: |
          # Define the state file
          STATE_FILE="terraform.tfstate"  # Default Terraform state file name

          # Check if the state file exists before uploading
          if [ -f "$STATE_FILE" ]; then
            echo "Uploading Terraform state file to the 'tfsate' directory..."
            aws s3 cp "$STATE_FILE" s3://"$STATE_BUCKET_NAME"/tfsate/"$STATE_BUCKET_NAME".tf --region "$REGION"
          else
            echo "Terraform state file not found, skipping upload."
          fi

      # Step 6: Upload Terraform lock file to S3
      - name: Upload Terraform lock file to S3
        run: |
          # Define the lock file
          LOCK_FILE="terraform.lock.hcl"  # Terraform lock file name

          # Check if the lock file exists before uploading
          if [ -f "$LOCK_FILE" ]; then
            echo "Uploading Terraform lock file to the 'tflock' directory..."
            aws s3 cp "$LOCK_FILE" s3://"$LOCK_BUCKET_NAME"/tflock/"$LOCK_BUCKET_NAME".hcl --region "$REGION"
          else
            echo "Terraform lock file not found, skipping upload."
          fi

      # Final Step: Output successful upload message
      - name: Final message
        run: |
          echo "Terraform state and lock files uploaded successfully to S3."
