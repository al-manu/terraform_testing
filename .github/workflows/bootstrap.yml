name: Create AWS Resources (S3 Buckets)

on:
  push:
    branches:
      - 'feature/*'  # Trigger on any push to a feature branch

jobs:
  create-resources:
    runs-on: ubuntu-latest
    permissions:
      id-token: write  # Required for OIDC
      contents: read   # Required for checking out the code
    environment:
      name: dev  # Adjust environment (prod, staging, etc.)
    
    env:
        AWS_ROLE_ARN: ${{ secrets.AWS_DEV_ROLE_ARN }}  # Use the AWS role for dev
        AWS_REGION: ${{ secrets.AWS_REGION }}  # Use the AWS region from secrets
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # Set up AWS credentials using OIDC authentication
      - name: Set up AWS OIDC credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}  # Use the environment variable
          aws-region: ${{ env.AWS_REGION }}  # Use the environment variable

      # Create S3 buckets for Terraform state and lock
      - name: Create S3 buckets for Terraform state and lock
        run: |
          # Define project name and environment
          PROJECT_NAME="dw-test"  # Replace with your project name
          ENVIRONMENT="dev"  # Can be dev, prod, etc.
          REGION="${{ secrets.AWS_REGION }}"

          # Define bucket names without slashes (valid S3 names)
          STATE_BUCKET_NAME="${PROJECT_NAME}-state-${ENVIRONMENT}"
          LOCK_BUCKET_NAME="${PROJECT_NAME}-lock-${ENVIRONMENT}"

          # Create the state bucket
          echo "Creating S3 bucket with name: $STATE_BUCKET_NAME"
          aws s3api create-bucket --bucket $STATE_BUCKET_NAME --create-bucket-configuration LocationConstraint=$REGION

          # Create the lock bucket
          echo "Creating S3 bucket with name: $LOCK_BUCKET_NAME"
          aws s3api create-bucket --bucket $LOCK_BUCKET_NAME --create-bucket-configuration LocationConstraint=$REGION

          # Output bucket names for use in subsequent workflows
          echo "state_bucket=$STATE_BUCKET_NAME" >> $GITHUB_ENV
          echo "lock_bucket=$LOCK_BUCKET_NAME" >> $GITHUB_ENV

          # Optionally, enable versioning for the state and lock buckets
          aws s3api put-bucket-versioning --bucket "$STATE_BUCKET_NAME" --versioning-configuration Status=Enabled
          aws s3api put-bucket-versioning --bucket "$LOCK_BUCKET_NAME" --versioning-configuration Status=Enabled

          echo "Created state and lock buckets: $STATE_BUCKET_NAME, $LOCK_BUCKET_NAME"

          # Generate the Terraform state file (this can be a Terraform init and apply)
          echo "Running Terraform to generate state file..."
          terraform init  # Initialize Terraform
          terraform apply -auto-approve  # Apply Terraform configuration (creates state file)

          # Check if the state file exists before uploading
          STATE_FILE="terraform.tfstate"  # This is the default Terraform state file name
          if [ -f "$STATE_FILE" ]; then
            echo "Uploading Terraform state file to simulated 'tfsate' directory..."
            aws s3 cp "$STATE_FILE" s3://"$STATE_BUCKET_NAME"/tfsate/terraform-state-file.tf
          else
            echo "Terraform state file not found, skipping upload."
          fi

          # Similarly, you can upload the Terraform lock file if it exists
          LOCK_FILE="terraform.lock.hcl"  # Terraform lock file
          if [ -f "$LOCK_FILE" ]; then
            echo "Uploading Terraform lock file to simulated 'tflock' directory..."
            aws s3 cp "$LOCK_FILE" s3://"$LOCK_BUCKET_NAME"/tflock/terraform-lock-file.hcl
          else
            echo "Terraform lock file not found, skipping upload."
          fi

          echo "Terraform state and lock files uploaded successfully."
