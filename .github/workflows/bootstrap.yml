name: Create and Manage AWS Resources (S3 Buckets)

on:
  push:
    branches:
      - 'feature/*'  # Trigger on any push to a feature branch

jobs:
  create-resources:
    runs-on: ubuntu-latest
    permissions:
      id-token: write  # Required for OIDC
      contents: read   # Required for checking out the code
    environment:
      name: dev  # Adjust environment (prod, staging, etc.)
    
    env:
      AWS_ROLE_ARN: ${{ secrets.AWS_DEV_ROLE_ARN }}  # AWS role for dev
      AWS_REGION: ${{ secrets.AWS_REGION }}  # AWS region from secrets
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up AWS OIDC credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Create S3 buckets for Terraform state and lock
        run: |
          # Define project name and environment dynamically
          PROJECT_NAME="dw-test"
          ENVIRONMENT="dev"  # This can be passed dynamically as an input
          REGION="${{ secrets.AWS_REGION }}"
          
          # Define bucket names dynamically
          STATE_BUCKET_NAME="${PROJECT_NAME}-state-${ENVIRONMENT}"
          LOCK_BUCKET_NAME="${PROJECT_NAME}-lock-${ENVIRONMENT}"

          # Check and create state bucket if it doesn't exist
          BUCKET_EXISTS=$(aws s3api head-bucket --bucket "$STATE_BUCKET_NAME" --region "$REGION" 2>&1 || true)
          if [[ "$BUCKET_EXISTS" == *"NotFound"* ]]; then
            echo "Creating state bucket: $STATE_BUCKET_NAME"
            aws s3api create-bucket --bucket "$STATE_BUCKET_NAME" --create-bucket-configuration LocationConstraint=$REGION
          else
            echo "State bucket $STATE_BUCKET_NAME already exists. Skipping creation."
          fi

          # Check and create lock bucket if it doesn't exist
          BUCKET_EXISTS=$(aws s3api head-bucket --bucket "$LOCK_BUCKET_NAME" --region "$REGION" 2>&1 || true)
          if [[ "$BUCKET_EXISTS" == *"NotFound"* ]]; then
            echo "Creating lock bucket: $LOCK_BUCKET_NAME"
            aws s3api create-bucket --bucket "$LOCK_BUCKET_NAME" --create-bucket-configuration LocationConstraint=$REGION
          else
            echo "Lock bucket $LOCK_BUCKET_NAME already exists. Skipping creation."
          fi

          # Output bucket names for use in the workflow
          echo "state_bucket=$STATE_BUCKET_NAME" >> $GITHUB_ENV
          echo "lock_bucket=$LOCK_BUCKET_NAME" >> $GITHUB_ENV

          # Optionally enable versioning for state and lock buckets
          aws s3api put-bucket-versioning --bucket "$STATE_BUCKET_NAME" --versioning-configuration Status=Enabled
          aws s3api put-bucket-versioning --bucket "$LOCK_BUCKET_NAME" --versioning-configuration Status=Enabled

          echo "Created state and lock buckets: $STATE_BUCKET_NAME, $LOCK_BUCKET_NAME"

      - name: Initialize and Apply Terraform
        run: |
          # Initialize Terraform with dynamic backend configuration
          terraform init \
            -backend-config="bucket=${{ env.state_bucket }}" \
            -backend-config="key=terraform/state/${PROJECT_NAME}-${ENVIRONMENT}.tfstate" \
            -backend-config="region=${{ secrets.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ env.lock_bucket }}"  # Locking with DynamoDB table (optional)
          
          # Apply Terraform configuration
          terraform apply -auto-approve

      - name: Upload Terraform State and Lock File to S3
        run: |
          # Upload state file to the correct S3 path
          STATE_FILE="terraform.tfstate"
          if [ -f "$STATE_FILE" ]; then
            echo "Uploading Terraform state file..."
            aws s3 cp "$STATE_FILE" s3://"$STATE_BUCKET_NAME"/tfsate/"$PROJECT_NAME"-${ENVIRONMENT}.tfstate
          else
            echo "Terraform state file not found, skipping upload."
          fi

          # Similarly, upload lock file if needed
          LOCK_FILE="terraform.lock.hcl"
          if [ -f "$LOCK_FILE" ]; then
            echo "Uploading Terraform lock file..."
            aws s3 cp "$LOCK_FILE" s3://"$LOCK_BUCKET_NAME"/tflock/"$PROJECT_NAME"-${ENVIRONMENT}.hcl
          else
            echo "Terraform lock file not found, skipping upload."
          fi
